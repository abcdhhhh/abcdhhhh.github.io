<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://abcdhhhh.github.io/atom.xml" rel="self"/>
  
  <link href="http://abcdhhhh.github.io/"/>
  <updated>2021-04-17T13:07:09.978Z</updated>
  <id>http://abcdhhhh.github.io/</id>
  
  <author>
    <name>abcdhhhh</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Dijkstra实现费用流</title>
    <link href="http://abcdhhhh.github.io/2021/02/15/Dijkstra%E5%AE%9E%E7%8E%B0%E8%B4%B9%E7%94%A8%E6%B5%81/"/>
    <id>http://abcdhhhh.github.io/2021/02/15/Dijkstra%E5%AE%9E%E7%8E%B0%E8%B4%B9%E7%94%A8%E6%B5%81/</id>
    <published>2021-02-15T11:55:30.000Z</published>
    <updated>2021-04-17T13:07:09.978Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>用SPFA求出源点到每个点的最短距离</p></li><li><p>为每个点 i 赋点权 h[i]为dis[i] ,并视每条连接 u,v 的边 i 的边权 w’[i] 为 w[i]+h[u]-h[v] 。</p><p>由于对于任意两点 u,v ,有<strong>w[u][v]+h[u]-h[v]≥0</strong> ,所以 w’ [i]≥0 ,这样一来新图上的 dis’[i] 就等于<strong> dis[i]+h[S]-h[i]</strong>。</p><p>由于每次跑最短路时 h[i] 都是不变的,所以求出了 dis’[i] 也就求出了 dis[i] ( dis[i]=dis’[i]-h[S]+h[i] ,其实很显然 h[S]=0 )</p></li></ol><pre class="mermaid">graph LR;    u((u))    v((v))    u--"w[u][v]+h[u]-h[v]"-->v</pre>]]></content>
    
    
    <summary type="html">我非要用Dijkstra</summary>
    
    
    
    <category term="ACM" scheme="http://abcdhhhh.github.io/categories/ACM/"/>
    
    
  </entry>
  
  <entry>
    <title>博弈模型</title>
    <link href="http://abcdhhhh.github.io/2021/02/15/%E5%8D%9A%E5%BC%88%E6%A8%A1%E5%9E%8B/"/>
    <id>http://abcdhhhh.github.io/2021/02/15/%E5%8D%9A%E5%BC%88%E6%A8%A1%E5%9E%8B/</id>
    <published>2021-02-15T11:55:30.000Z</published>
    <updated>2021-04-17T13:29:00.874Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Fibonacci博弈"><a href="#Fibonacci博弈" class="headerlink" title="Fibonacci博弈"></a>Fibonacci博弈</h4><p>一堆$n$个石子，两人轮流取，每次最少取1个，最多不超过对手刚取的个数的2倍（第一次无限制，但不能取完）。取完获胜。</p><p>先手必败当且仅当$n$为Fibonacci数。</p><h4 id="Wythoff博弈"><a href="#Wythoff博弈" class="headerlink" title="Wythoff博弈"></a>Wythoff博弈</h4><p>两堆各若干个石子，两人轮流从一堆中取任意个或从两堆中取同样多个。每次至少取1个，取光者胜利。</p><p>定义后手必胜的局面为奇异局势。</p><p>从小到大依次为 $(0,0), (1,2), (3,5), …$</p><p>（可以考虑方格纸上，从左下角依次放点，每个点可以向上、右、右上方向发出射线）</p><p>设第$k$个局面为$(a_k,b_k)$，则$a_k-a_{k-1}=k, b_k=[\frac{1+\sqrt{5}}{2}a_k]$</p><h4 id="nim-k游戏"><a href="#nim-k游戏" class="headerlink" title="nim-k游戏"></a>nim-k游戏</h4><p>有n堆石子，每次可以从至多k堆中拿走任意数量的石子。（可以每堆拿的不一样）</p><p>不能拿的输。</p><p>先手必胜条件：把n堆石子用二进制表示，统计每一位上面的1的个数，如果每一位1的个数 mod (k+1)全为0，则先手必败。否则先手必胜。</p><p>证明：类比一堆石子共n个，每次去1~m个，不能动为输。</p><p>（比较显然，考虑不全是0的时候，从高位到低位取成0，如果这位的数比之前少，那么可以在前面不全去完，而是剩一些，在这里加个1之类的，比之前多就把新的弄小</p><h4 id="二分图博弈"><a href="#二分图博弈" class="headerlink" title="二分图博弈"></a>二分图博弈</h4><p>给一张二分图和一个起点，轮流在上面走，不能走重复的点，不能走就输。</p><p>先手必败当且仅当存在一个最大匹配使得起点不在这个匹配里面。（去掉起点跑最大匹配，加回来再跑一次，增广了就是先手败）</p><p>结论可以扩展到一般图上面，结论不变。</p><p>二分图证明：因为是二分图，停在起点一边就是先手败，否则后手败。</p><p>如果起点可以不在最大匹配：先手随便走，后手按照匹配边走。这样不可能停在另一边，否则就是一条增广路。</p><p>如果起点必须在最大匹配：先手按照固定的一个最大匹配走，随便后手怎么走，最后如果是停在先手一边，说明是$k$条匹配边，$k$条非匹配边，并且终点一定是一个非匹配点，否则先手还能走。异或一下就是一个不包括起点的最大匹配。</p><p>这个证明也适用于一般图。</p>]]></content>
    
    
    <summary type="html">你会玩吗？</summary>
    
    
    
    <category term="ACM" scheme="http://abcdhhhh.github.io/categories/ACM/"/>
    
    
  </entry>
  
  <entry>
    <title>后缀自动机中的extend操作</title>
    <link href="http://abcdhhhh.github.io/2021/02/01/%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%AD%E7%9A%84extend%E6%93%8D%E4%BD%9C/"/>
    <id>http://abcdhhhh.github.io/2021/02/01/%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%AD%E7%9A%84extend%E6%93%8D%E4%BD%9C/</id>
    <published>2021-02-01T07:40:54.000Z</published>
    <updated>2021-04-17T13:06:41.650Z</updated>
    
    <content type="html"><![CDATA[<p>后缀自动机extend操作的代码如下。每次插入，会新建1~2个节点。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">extend</span><span class="params">(<span class="keyword">char</span> c)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> cur = sz++; <span class="comment">// new state</span></span><br><span class="line">st[cur].init();</span><br><span class="line">st[cur].len = st[last].len + <span class="number">1</span>; <span class="comment">// length</span></span><br><span class="line"><span class="keyword">int</span> p = last;</span><br><span class="line"><span class="keyword">while</span>(p != <span class="number">-1</span> &amp;&amp; st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] == <span class="number">-1</span>) &#123;</span><br><span class="line">st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] = cur;</span><br><span class="line">p = st[p].link;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(p == <span class="number">-1</span>) &#123;</span><br><span class="line">st[cur].link = <span class="number">0</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">int</span> q = st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>];</span><br><span class="line"><span class="keyword">if</span>(st[p].len + <span class="number">1</span> == st[q].len) &#123; <span class="comment">// no other state</span></span><br><span class="line">st[cur].link = q;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">int</span> clone = sz++;</span><br><span class="line">st[clone].len = st[p].len + <span class="number">1</span>;</span><br><span class="line">st[clone].link = st[q].link;</span><br><span class="line">rep(i, <span class="number">0</span>, <span class="number">25</span>) st[clone].nxt[i] = st[q].nxt[i];</span><br><span class="line"><span class="keyword">while</span>(p != <span class="number">-1</span> &amp;&amp; st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] == q)&#123;</span><br><span class="line">st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] = clone; <span class="comment">// transfer</span></span><br><span class="line">p = st[p].link;</span><br><span class="line">&#125;</span><br><span class="line">st[q].link = st[cur].link = clone;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">last = cur;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>下面将用一些实例具体说明。</p><p>（定义“等价后缀”为在串中出现（末）位置集合完全相同的后缀。）</p><p>例1：$s=”a”+”b”$</p><pre class="mermaid">graph LR;0((t0));style 0 fill:#f55, stroke:#5f5,stroke-width:2px;1((a));style 1 fill:#fff, stroke:#5f5,stroke-width:2px;2((ab));style 2 fill:#f55;0--a-->1;1-.->0;1--b-->2;linkStyle 2 stroke:#5f5,stroke-width:2px;0--b-->2;linkStyle 3 stroke:#5f5,stroke-width:2px;2-.->0;linkStyle 4 stroke:#f55,stroke-width:2px,stroke-dasharray:5,5;</pre><p>没有非等价后缀。</p><p>例2：$s=”ab”+”a”$</p><pre class="mermaid">graph LR;0((t0));style 0 fill:#f55, stroke:#5f5,stroke-width:2px;1((a));style 1 fill:#f55;2((ab));style 2 fill:#fff, stroke:#5f5,stroke-width:2px;3((aba));style 3 fill:#f55;0--a-->1;1-.->0;1--b-->2;0--b-->2;2-.->0;2--a-->3;linkStyle 5 stroke:#5f5,stroke-width:2px;linkStyle 0 stroke:#55f,stroke-width:2px;3-.->1;linkStyle 6 stroke:#f55,stroke-width:2px,stroke-dasharray:5,5;</pre><p>前一个非等价后缀是”a”。</p><p>例3：$s=”ab”+”b”$</p><pre class="mermaid">graph LR;0((t0));style 0 fill:#f55, stroke:#5f5,stroke-width:2px;1((a));style 1 fill:#fff;2((ab));style 2 fill:#fff, stroke:#5f5,stroke-width:2px;3((abb));style 3 fill:#f55;0--a-->1;1-.->0;1--b-->2;0--"b(deleted)"-->2;2-."(deleted)".->0;2--b-->3;linkStyle 5 stroke:#5f5,stroke-width:2px;4((b));style 4 fill:#f55;4--b-->3;linkStyle 6 stroke:#d6d,stroke-width:2px;0--b-->4;linkStyle 7 stroke:#d6d,stroke-width:2px;3-.->4;linkStyle 8 stroke:#f55,stroke-width:2px,stroke-dasharray:5,5;4-.->0;linkStyle 9 stroke:#f55,stroke-width:2px,stroke-dasharray:5,5;2-.->4;linkStyle 10 stroke:#d6d,stroke-width:2px,stroke-dasharray:5,5;</pre><p>前一个非等价后缀是”b”，但”b”在原先表示”ab”的节点上，因此还需要把”b”状态分离一份出来，作为”ab”和”abb”的前一个非等价后缀。</p>]]></content>
    
    
    <summary type="html">状态冲突与调解</summary>
    
    
    
    <category term="ACM" scheme="http://abcdhhhh.github.io/categories/ACM/"/>
    
    
  </entry>
  
  <entry>
    <title>ML笔记</title>
    <link href="http://abcdhhhh.github.io/2021/01/29/ML%E7%AC%94%E8%AE%B0/"/>
    <id>http://abcdhhhh.github.io/2021/01/29/ML%E7%AC%94%E8%AE%B0/</id>
    <published>2021-01-29T14:45:43.000Z</published>
    <updated>2021-04-17T13:53:25.909Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p><pre class="mermaid">graph TD;ts(Training set);la(Learning algorithm);h(hypothesis function);1((x))2((y))ts-->la-->h;1-->h-->2;</pre></p><h1 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h1><p>$\{(x^{(i)},y^{(i)})|i=1,2,…,m\}$<br>$x_j^{(i)}$表示第$i$个训练数据的第$j$个特征。</p><h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h2><p>$x_i:=\frac{x_i-\bar{x}}{\sigma}$</p><h1 id="回归问题——线性回归"><a href="#回归问题——线性回归" class="headerlink" title="回归问题——线性回归"></a>回归问题——线性回归</h1><p>令$x_0=1$，$x=\begin{bmatrix}x_0\\x_1\...\\x_n\end{bmatrix}$，$\theta=\begin{bmatrix}\theta_0\\\theta_1\...\\\theta_n\end{bmatrix}$。<br>hypothesis函数：$h_\theta (x)=\theta^Tx$。<br>总cost函数：$J(\theta)=\frac{1}{2}\text{mean}(||h-y||^2)$</p><p>（多项式回归：将$x_1^2, x_1x_2^3$等高次项作为特征）</p><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>不断迭代：$\theta :=\theta-\alpha \nabla J(\theta)$<br>其中：</p><ul><li>$\alpha$为学习速率</li><li>$\nabla J(\theta)=\text{mean}(x(h-y))$为梯度</li></ul><h2 id="一般方程"><a href="#一般方程" class="headerlink" title="一般方程"></a>一般方程</h2><p>求$X\theta=y$的最小二乘解：$\theta=(X^TX)^{-1}X^Ty$</p><p>（若$X^TX$不可逆，可能是feature过多）</p><h1 id="二分类问题——logistic回归"><a href="#二分类问题——logistic回归" class="headerlink" title="二分类问题——logistic回归"></a>二分类问题——logistic回归</h1><p>sigmoid函数：$g(z)=\frac{1}{1+e^{-z}}$。<br>hypothesis函数：$h_\theta (x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}=P(y=1|x;\theta)$。</p><p>决策函数：$y=[h_\theta(x)&gt;0.5]$<br>决策边界： $h_\theta(x)=0.5$，即$\theta^Tx=0$。</p><p>cost函数：</p><script type="math/tex; mode=display">\text{Cost}(h_\theta(x),y)=\begin{cases}-\log(h_\theta(x))&y=1\\-\log(1-h_\theta(x))& y=0\end{cases}\\=-y\log(h_\theta(x))-(1-y)\log(1-h_\theta(x))</script><p>总cost函数：</p><script type="math/tex; mode=display">J(\theta)=\text{meanCost}(h_\theta(x),y)\\=-\text{mean}(y\log(h)+(1-y)\log(1-h))\\=\text{mean}(y\log(1+e^{-\theta^Tx})+(1-y)\log(1+e^{\theta^Tx}))</script><h2 id="梯度下降法-1"><a href="#梯度下降法-1" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>不断迭代：$\theta :=\theta-\alpha \nabla J(\theta)$<br>其中：</p><ul><li>$\nabla J(\theta)=\text{mean}(x(h-y))$为梯度</li></ul><p>（多分类问题：面对每个新的数据集，都逐类进行检验（把要检验的类当作1，其余当作0），选择可能性最高的那类）</p><h3 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h3><p>对于规模较大的数据集，可以随机选一个样本算cost</p><h3 id="online-learning"><a href="#online-learning" class="headerlink" title="online learning"></a>online learning</h3><p>每次获得一个新的训练集，都用它的cost进行一次梯度下降</p><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>增加penalty以控制$\theta$规模。（$\theta_0$除外）</p><ul><li>L1范数（绝对值和）：Lasso回归</li><li>L2范数（平方和）：岭回归</li></ul><p>回归问题<br>$J(\theta)=\frac{1}{2}\text{mean}(||h-y||^2+\frac{\lambda}{2m}(||\theta||^2)$<br>分类问题</p><p>$J(\theta)=-\frac{1}{m}(y^T\log(h)+(1-y)^T\log(1-h))+\frac{\lambda}{2m}(||\theta||^2)$</p><p>$\theta_j :=\theta_j(1-\alpha\frac{\lambda}{m})-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} (j\ne 0)$</p><p>一般方程<br>$\theta=(X^TX+\lambda \begin{bmatrix}0&amp;O\\O&amp;I_n\end{bmatrix})^{-1}X^Ty$<br>（可以解决矩阵不可逆的问题）</p><h2 id="overfit与underfit"><a href="#overfit与underfit" class="headerlink" title="overfit与underfit"></a>overfit与underfit</h2><div class="table-container"><table><thead><tr><th></th><th>overfit: high variance</th><th>underfit: high bias</th></tr></thead><tbody><tr><td></td><td>$J_{CV}&gt;&gt;J_{train}&gt;0$</td><td>$J_{CV}&gt;J_{train}&gt;&gt;0$</td></tr><tr><td>fix</td><td>fewer features, <strong>more examples</strong>, increase $\lambda$</td><td>more/polynomial features, decrease $\lambda$</td></tr></tbody></table></div><h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p>神经网络是一个多层感知机。从输入到输出共有$L$层，第$l$层$a^{(l)}$有$s_l$个unit。（$K$分类问题中$s_L=K$）</p><p>相邻两层之间的转移是Logistic回归（一个线性变换+一个sigmoid函数）：</p><p>$z^{(l+1)}=W^{(l)}a^{(l)}+b^{(l)}, a^{(l+1)}=g(z^{(l+1)})$</p><p>其中$W^{(l)}\in R^{s_{l+1}\times s_l}, b^{(l)}\in R^{s_{l+1}}$，$g(z)=\frac{1}{1+e^{-z}}$。</p><p>$J=-\text{mean}(y\log h-(1-y)\log (1-h))+||W||^2$</p><p>我们的目标是求$W,b$以最小化$J$。</p><p>梯度下降法需要知道每一步的$\frac{\partial}{\partial W_{i,j}^{(l)}}J$以及$\frac{\partial}{\partial b_{i}^{(l)}}J$。</p><h2 id="Hadamard积"><a href="#Hadamard积" class="headerlink" title="Hadamard积"></a>Hadamard积</h2><p>即矩阵对应位置元素乘积运算。</p><p>$S_{n\times m}\circ T_{n\times m}=\begin{bmatrix}s_{11}t_{11}&amp;s_{12}t_{12}&amp;…&amp;s_{1m}t_{1m}\\ s_{21}t_{21}&amp;s_{22}t_{22}&amp;…&amp;s_{2m}t_{2m}\\ …&amp;…&amp;…&amp;…\\ s_{n1}t_{n1}&amp;s_{n2}t_{n2}&amp;…&amp;s_{nm}t_{nm}\end{bmatrix}$</p><h2 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h2><p><a href="https://blog.csdn.net/qq_47903865/article/details/113839061">https://blog.csdn.net/qq_47903865/article/details/113839061</a></p><h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><p>目标：</p><p>$\min_\theta C\sum(y \text{cost}_1(\theta^Tx)+(1-y)\text{cost}_0(\theta^Tx))+\frac{1}{2}||\theta||^2$</p><p>其中$C=\frac{1}{\lambda}$</p><p><img src="ML笔记.assets/image-20210214094906957.png" alt="image-20210214094906957"></p><p>当 $\begin{cases}\theta^Tx\ge 1&amp;h=1\\\theta^Tx\le -1&amp;h=0\end{cases}$时，$y \text{cost}_1(\theta^Tx)+(1-y)\text{cost}_0(\theta^Tx)=0$。</p><h2 id="tip-Gaussian-kernal"><a href="#tip-Gaussian-kernal" class="headerlink" title="tip: Gaussian kernal"></a>tip: Gaussian kernal</h2><p>选取landmark $l$，利用<strong>正态分布</strong>曲线：</p><p>$f=\exp(-\frac{||z-l||^2}{2\sigma^2})$</p><div class="table-container"><table><thead><tr><th></th><th>high bias, low variance</th><th>low bias, high variance</th></tr></thead><tbody><tr><td>$C(=\frac{1}{\lambda})$</td><td>small</td><td>large</td></tr><tr><td>$\sigma^2$</td><td>large</td><td>small</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>$n$ large(&gt;10,000), $m$(&lt;1,000)</th><th>$n$ small(&lt;1,000), $m$ intermediate(&lt;10,000)</th><th>$n$ small(<1,000), $m$ large(>50,000)</th></tr></thead><tbody><tr><td>linear kernel</td><td>Gaussian kernel</td><td>add features+linear kernel</td></tr></tbody></table></div><h2 id="tip-扩大数据规模"><a href="#tip-扩大数据规模" class="headerlink" title="tip: 扩大数据规模"></a>tip: 扩大数据规模</h2><p>在原数据上增加干扰</p><h2 id="tip-map-reduce"><a href="#tip-map-reduce" class="headerlink" title="tip: map reduce"></a>tip: map reduce</h2><p>把训练集分给多台计算机并行计算。</p><h2 id="tip-上限分析"><a href="#tip-上限分析" class="headerlink" title="tip: 上限分析"></a>tip: 上限分析</h2><p>分析机器学习流水线各阶段准确率上限，从而避免无用功</p><h1 id="聚类问题"><a href="#聚类问题" class="headerlink" title="聚类问题"></a>聚类问题</h1><p>将训练集分成多个团</p><h2 id="K-means算法"><a href="#K-means算法" class="headerlink" title="K-means算法"></a>K-means算法</h2><ol><li>随机初始化$K$个质心$\mu_1,\mu_2,…,\mu_K$（可以随机取$K$个训练数据）</li><li>找出每个点最近的质心$\mu_{c^{(i)}}$，并将质心更新为其关联点的均值。不断迭代。</li></ol><p>optimization objective: $J(c,\mu)=\text{mean}(||x^{(i)}-\mu_{c^{(i)}}||^2)$</p><p>可能会取局部极小值，因此需多次实验</p><p>全局最小值随$K$递减</p><h1 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h1><p>把$n$维数据集$X=\{x_1,x_2,…,x_m\}\in R^{n\times m}$</p><p>降到$k$维$Y\in R^{k\times m}$</p><h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><ol><li>feature scaling，去中心化</li><li>求出协方差矩阵$\Sigma=\frac{1}{m}XX^T$，进行特征值分解$\Sigma=U^T\Lambda U$</li><li>取$U$前$k$列，组成$P\in R^{n\times k}$</li><li>$Y=P^TX$，$X_{approx}=PY$</li></ol><p>choice of $k$ :  $\frac{\sum_{i=1}^k\lambda_i}{\sum_{i=1}^n\lambda_i}\ge 0.99$</p><p>可以减小数据规模、方便可视化</p><p>不推荐用来处理overfit（更推荐正则化）</p><h1 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h1><p>根据训练集，确定数据的异常程度</p><h2 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h2><p>训练集$X=\{x_1,x_2,…,x_m\}\in R^{n\times m}$</p><p>一维：$p(x;\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x-\mu)^2}{2\sigma^2})$。</p><p>$p(x)=\prod_{i=1}^n p(x_i;\mu_i,\sigma_i)$。</p><p>$n$维：$p(x;\mu,\sigma)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}\exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))$，其中$\Sigma$为协方差矩阵。（要求$m&gt;n$，否则$\Sigma$不可逆）</p><p>决策函数：$y=[p(x)\le \varepsilon]$</p><p>评价依据：F1分数（精准率和召回率的调和平均数）</p><div class="table-container"><table><thead><tr><th>异常检测</th><th>监督学习</th></tr></thead><tbody><tr><td>少量异常样本，大量正常样本</td><td>正常、异常样本数目接近</td></tr><tr><td>异常样本缺乏共性</td><td>异常样本有共性</td></tr></tbody></table></div><h1 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h1><p>$n_u$个用户，$n_m$部电影，用户$j$对电影$i$的评分为$y(i,j)$，有缺失。</p><h2 id="协同过滤"><a href="#协同过滤" class="headerlink" title="协同过滤"></a>协同过滤</h2><p>电影$i$有特征$x^{(i)}$，用户$j$有偏好$\theta^{(j)}$。</p><p>先随机初始化$X$和$\Theta$。</p><p>然后梯度下降，目标函数$J(X,\Theta)=\frac{1}{2}||X\Theta^T-Y||^2+\frac{\lambda}{2}||X||^2+\frac{\lambda}{2}||\Theta||^2$。</p><p>对缺失的$y(i,j)$，可补齐缺失评分$y(i,j)=\theta^{(j)T}x^{(i)}$。</p><p>推荐时，选择缺失评分较高的几个电影。</p>]]></content>
    
    
    <summary type="html">举一反三的原理</summary>
    
    
    
    <category term="ML" scheme="http://abcdhhhh.github.io/categories/ML/"/>
    
    
  </entry>
  
  <entry>
    <title>图的计数</title>
    <link href="http://abcdhhhh.github.io/2021/01/29/%E5%9B%BE%E7%9A%84%E8%AE%A1%E6%95%B0/"/>
    <id>http://abcdhhhh.github.io/2021/01/29/%E5%9B%BE%E7%9A%84%E8%AE%A1%E6%95%B0/</id>
    <published>2021-01-29T14:45:43.000Z</published>
    <updated>2021-04-17T13:31:36.652Z</updated>
    
    <content type="html"><![CDATA[<h1 id="无标号计数"><a href="#无标号计数" class="headerlink" title="无标号计数"></a>无标号计数</h1><h2 id="1、二叉树"><a href="#1、二叉树" class="headerlink" title="1、二叉树"></a>1、二叉树</h2><p>设OGF为$H(x)=\sum_{i=0}^{\infty}h_ix^i$。<br>任意一棵大小为$n(n\ge 1)$二叉树去掉根，可以得到两棵大小之和为$n-1$的二叉树。因此$h_n=\sum_{i=0}^{n-1}h_ih_{n-1-i}(n\ge 1)$。</p><p>根据递推关系可列出方程$xH(x)^2-H(x)+1=0$。<br>解得$H(x)=\frac{1-\sqrt{1-4x}}{2x}$。<br>求得$h_n=\frac{\binom{2n}{n}}{n+1}$。</p><h2 id="预备知识：Euler变换"><a href="#预备知识：Euler变换" class="headerlink" title="*预备知识：Euler变换"></a>*预备知识：Euler变换</h2><p>Euler变换在无标号计数中的组合意义相当于有标号计数中的exp，即阶数之和为$n$的结构的任意组合。</p><p>设$F(x)=\sum_{i=0}^{\infty}f_ix^i$。<br>定义$\mathcal{E}(F(x))=\prod_{i=0}^\infty \frac{1}{(1-x^i)^{f_i}}$。<br>上式可化为$\mathcal{E}(F(x))=\exp(\sum_{i=1}^\infty\frac{F(x^i)}{i})$。</p><h2 id="2、有根树"><a href="#2、有根树" class="headerlink" title="2、有根树"></a>2、有根树</h2><p>设OGF为$F(x)=\sum_{i=0}^\infty f_ix^i$。<br>任意一棵大小为$n(n\ge 1)$的有根树去掉根，可以得到若干棵大小之和为$n-1$的有根树。因此$F(x)=x\mathcal{E}(F(x))$。</p><h2 id="2-、无根树"><a href="#2-、无根树" class="headerlink" title="2*、无根树"></a>2*、无根树</h2><p>设有根树的OGF为$F(x)=\sum_{i=0}^\infty f_ix^i$，无根树的OGF为$H(x)=\sum_{i=0}^\infty h_ix^i$。<br>要统计无根树，只需统计以重心为根的有根树。根据重心的定义一个点是重心当且仅当它的每棵子树大小不超过$[\frac{n}{2}]$。<br>因此，一棵树有2个重心当且仅当重心最大子树的大小<strong>恰好</strong>是$\frac{n}{2}$，否则只有1个重心。当树有两个重心时，也要把重心重复计算的情况给减去。<br>因此，$h_n=\begin{cases}f_n-\sum_{k=\frac{n+1}{2}}^{n-1}f_kf_{n-k}&amp;n为奇数\\f_n-\sum_{k=\frac{n}{2}+1}^{n-1}f_kf_{n-k}-\binom{f_{\frac{n}{2}}}{2}&amp;n为偶数\end{cases}$。<br>即$H(x)=F(x)-\frac{1}{2}F(x)^2+F(x^2)$。</p><h1 id="有标号计数"><a href="#有标号计数" class="headerlink" title="有标号计数"></a>有标号计数</h1><h2 id="1、无根树"><a href="#1、无根树" class="headerlink" title="1、无根树"></a>1、无根树</h2><p>由<a href=https://oi-wiki.org/graph/prufer/>Prufer序列</a>和无根树的一一对应关系，得答案$n^{n-2}$。</p><h2 id="1-、有根树"><a href="#1-、有根树" class="headerlink" title="1*、有根树"></a>1*、有根树</h2><p>答案$n^{n-1}$。</p><h2 id="2、无向连通图"><a href="#2、无向连通图" class="headerlink" title="2、无向连通图"></a>2、无向连通图</h2><p>设$n$阶有标号无向连通图有$f_n$种。<br>设$F(x)=\sum_{i=0}^\infty \frac{f_i}{i!}x^i$。<br>则$\exp F(x)=\sum_{i=0}^\infty\frac{2^\binom{i}{2}}{i!}x^i$。<br>即$F(x)=\ln\sum_{i=0}^\infty\frac{2^\binom{i}{2}}{i!}x^i$</p><h2 id="3、点双连通图"><a href="#3、点双连通图" class="headerlink" title="3、点双连通图"></a>3、点双连通图</h2><p>设无向连通图的EGF为$F(x)$，有根无向连通图的EGF为$D(x)$，则$[x^n]F(x)=n[x^n]D(x)$。<br>设点双连通图的EGF为$B(x)$。<br>任意一个大小为$n$的有根无向连通图去掉根都可以得到若干个大小之和为$n-1$的连通块。对每个连通块，考虑根所在的点双连通分量，每个点作为根，都可以向外连出一个有根无向连通图。<br>因此一个连通块的EGF为$\sum_{i=1}^\infty \frac{b_{i+1}D^i(x)}{i!}=B’(D(x))$。<br>因此$D(x)=\exp B’(D(x))$。</p><h2 id="4、边双连通图"><a href="#4、边双连通图" class="headerlink" title="4、边双连通图"></a>4、边双连通图</h2><p>设有根无向连通图的EGF为$D(x)$，边双连通图的EGF为$B(x)$。<br>考虑根所在的边双连通分量，每个点都可以向外连接若干个有根无向连通图的根。<br>因此$D(x)=\sum_{i=1}^\infty \frac{b_ix^i\exp iD(x)}{i!}=B(x\exp D(x))$</p><h2 id="5、仙人掌"><a href="#5、仙人掌" class="headerlink" title="5、仙人掌"></a>5、仙人掌</h2><p>设EGF为$F(x)=\sum_{i=0}^\infty \frac{f_i}{i!}x^i$。<br>$F=x\exp (F+\frac{1}{2}\sum_{i=2}^\infty F^i)=x\exp \frac{F(2-F)}{2(1-F)}$</p><h2 id="6、DAG"><a href="#6、DAG" class="headerlink" title="6、DAG"></a>6、DAG</h2><p>设EGF为$F(x)=\sum_{i=0}^\infty \frac{f_i}{i!}x^i$。<br>$f_n=\sum_{i=1}^n(-1)^{i-1}\binom{n}{i}2^{i(n-i)}f_{n-i}$。</p><h2 id="7、欧拉图"><a href="#7、欧拉图" class="headerlink" title="7、欧拉图"></a>7、欧拉图</h2><p>设EGF为$F(x)=\sum_{i=0}^\infty \frac{f_i}{i!}x^i$。每个点度数均为偶数的图的EGF为$G(x)=\sum_{i=0}^\infty \frac{g_i}{i!}x^i$。<br>对于任意一个$n-1$阶的图，都可以新加一个点$n$，与图中所有度数为奇数的点连边。<br>因此$g_n=2^\binom{n-1}{2}$。<br>而$G(x)=\exp F(x)$。<br>因此$F(x)=\ln G(x)$。</p>]]></content>
    
    
    <summary type="html">永远学不会的多项式，永远理不清的递推关系</summary>
    
    
    
    <category term="组合数学" scheme="http://abcdhhhh.github.io/categories/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/"/>
    
    
  </entry>
  
  <entry>
    <title>小记</title>
    <link href="http://abcdhhhh.github.io/2021/01/29/%E5%B0%8F%E8%AE%B0/"/>
    <id>http://abcdhhhh.github.io/2021/01/29/%E5%B0%8F%E8%AE%B0/</id>
    <published>2021-01-29T10:08:45.000Z</published>
    <updated>2021-02-21T08:07:17.745Z</updated>
    
    <content type="html"><![CDATA[<p>没啥特别的目的，主要想体验一下建站是一种什么感觉<del>以及不喜欢CSDN的界面风格</del>。<br>关于写啥内容，暂时还没啥明确的想法。希望能早日写出一些有价值的东西吧。</p><p>没有太多可说的，那就放一首歌吧。</p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1389794615&auto=1&height=66"></iframe>]]></content>
    
    
    <summary type="html">写在建站之后</summary>
    
    
    
    <category term="随笔" scheme="http://abcdhhhh.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
</feed>
