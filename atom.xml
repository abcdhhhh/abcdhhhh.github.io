<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://abcdhhhh.github.io/atom.xml" rel="self"/>
  
  <link href="http://abcdhhhh.github.io/"/>
  <updated>2021-02-02T13:23:48.545Z</updated>
  <id>http://abcdhhhh.github.io/</id>
  
  <author>
    <name>abcdhhhh</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>后缀自动机中的extend操作</title>
    <link href="http://abcdhhhh.github.io/2021/02/01/%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%AD%E7%9A%84extend%E6%93%8D%E4%BD%9C/"/>
    <id>http://abcdhhhh.github.io/2021/02/01/%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%AD%E7%9A%84extend%E6%93%8D%E4%BD%9C/</id>
    <published>2021-02-01T07:40:54.000Z</published>
    <updated>2021-02-02T13:23:48.545Z</updated>
    
    <content type="html"><![CDATA[<p>后缀自动机extend操作的代码如下。每次插入，会新建1~2个节点。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">extend</span><span class="params">(<span class="keyword">char</span> c)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> cur = sz++; <span class="comment">// new state</span></span><br><span class="line">st[cur].init();</span><br><span class="line">st[cur].len = st[last].len + <span class="number">1</span>; <span class="comment">// length</span></span><br><span class="line"><span class="keyword">int</span> p = last;</span><br><span class="line"><span class="keyword">while</span>(p != <span class="number">-1</span> &amp;&amp; st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] == <span class="number">-1</span>) &#123;</span><br><span class="line">st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] = cur;</span><br><span class="line">p = st[p].link;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(p == <span class="number">-1</span>) &#123;</span><br><span class="line">st[cur].link = <span class="number">0</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">int</span> q = st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>];</span><br><span class="line"><span class="keyword">if</span>(st[p].len + <span class="number">1</span> == st[q].len) &#123; <span class="comment">// no other state</span></span><br><span class="line">st[cur].link = q;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">int</span> clone = sz++;</span><br><span class="line">st[clone].len = st[p].len + <span class="number">1</span>;</span><br><span class="line">st[clone].link = st[q].link;</span><br><span class="line">rep(i, <span class="number">0</span>, <span class="number">25</span>) st[clone].nxt[i] = st[q].nxt[i];</span><br><span class="line"><span class="keyword">while</span>(p != <span class="number">-1</span> &amp;&amp; st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] == q)&#123;</span><br><span class="line">st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] = clone; <span class="comment">// transfer</span></span><br><span class="line">p = st[p].link;</span><br><span class="line">&#125;</span><br><span class="line">st[q].link = st[cur].link = clone;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">last = cur;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>下面将用一些实例具体说明。</p><p>（定义“等价后缀”为在串中出现（末）位置集合完全相同的后缀。）</p><p>例1：$s=”a”+”b”$</p><pre class="mermaid">graph LR;0((t0));style 0 fill:#f55, stroke:#5f5,stroke-width:2px;1((a));style 1 fill:#fff, stroke:#5f5,stroke-width:2px;2((ab));style 2 fill:#f55;0--a-->1;1-.->0;1--b-->2;linkStyle 2 stroke:#5f5,stroke-width:2px;0--b-->2;linkStyle 3 stroke:#5f5,stroke-width:2px;2-.->0;linkStyle 4 stroke:#f55,stroke-width:2px,stroke-dasharray:5,5;</pre><p>没有非等价后缀。</p><p>例2：$s=”ab”+”a”$</p><pre class="mermaid">graph LR;0((t0));style 0 fill:#f55, stroke:#5f5,stroke-width:2px;1((a));style 1 fill:#f55;2((ab));style 2 fill:#fff, stroke:#5f5,stroke-width:2px;3((aba));style 3 fill:#f55;0--a-->1;1-.->0;1--b-->2;0--b-->2;2-.->0;2--a-->3;linkStyle 5 stroke:#5f5,stroke-width:2px;linkStyle 0 stroke:#55f,stroke-width:2px;3-.->1;linkStyle 6 stroke:#f55,stroke-width:2px,stroke-dasharray:5,5;</pre><p>前一个非等价后缀是”a”。</p><p>例3：$s=”ab”+”b”$</p><pre class="mermaid">graph LR;0((t0));style 0 fill:#f55, stroke:#5f5,stroke-width:2px;1((a));style 1 fill:#fff;2((ab));style 2 fill:#fff, stroke:#5f5,stroke-width:2px;3((abb));style 3 fill:#f55;0--a-->1;1-.->0;1--b-->2;0--"b(deleted)"-->2;2-."(deleted)".->0;2--b-->3;linkStyle 5 stroke:#5f5,stroke-width:2px;4((b));style 4 fill:#f55;4--b-->3;linkStyle 6 stroke:#d6d,stroke-width:2px;0--b-->4;linkStyle 7 stroke:#d6d,stroke-width:2px;3-.->4;linkStyle 8 stroke:#f55,stroke-width:2px,stroke-dasharray:5,5;4-.->0;linkStyle 9 stroke:#f55,stroke-width:2px,stroke-dasharray:5,5;2-.->4;linkStyle 10 stroke:#d6d,stroke-width:2px,stroke-dasharray:5,5;</pre><p>前一个非等价后缀是”b”，但”b”在原先表示”ab”的节点上，因此还需要把”b”状态分离一份出来，作为”ab”和”abb”的前一个非等价后缀。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;后缀自动机extend操作的代码如下。每次插入，会新建1~2个节点。&lt;br&gt;&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;sp</summary>
      
    
    
    
    <category term="ACM" scheme="http://abcdhhhh.github.io/categories/ACM/"/>
    
    
    <category term="后缀自动机" scheme="http://abcdhhhh.github.io/tags/%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA/"/>
    
    <category term="字符串" scheme="http://abcdhhhh.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
    
  </entry>
  
  <entry>
    <title>【gym_102878E】Eigen Substring（后缀自动机）</title>
    <link href="http://abcdhhhh.github.io/2021/02/01/%E3%80%90gym_102878E%E3%80%91Eigen%20Substring%EF%BC%88%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA%EF%BC%89/"/>
    <id>http://abcdhhhh.github.io/2021/02/01/%E3%80%90gym_102878E%E3%80%91Eigen%20Substring%EF%BC%88%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA%EF%BC%89/</id>
    <published>2021-02-01T06:49:21.000Z</published>
    <updated>2021-02-02T13:23:33.549Z</updated>
    
    <content type="html"><![CDATA[<h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>如果字符串$s$的子串$s[l..r]$在$s$中只出现一次，那么称它为$s$的<strong>特征子串</strong>。</p><p>给定字符串$s$，询问它的<strong>每个前缀</strong>的最短特征子串的长度。</p><h2 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h2><p>共两行。<br>第一行一个整数$n(1\le n\le 10^6)$，表示$s$的长度。<br>第二行一个字符串$s$，所有字符均为英文小写字母。</p><h2 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h2><p>共$n$行。<br>第$i$行一个整数，表示字符串$s[1..i]$的最短特征子串的长度。</p><h2 id="输入样例"><a href="#输入样例" class="headerlink" title="输入样例"></a>输入样例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5</span><br><span class="line">ababb</span><br></pre></td></tr></table></figure><h2 id="输出样例"><a href="#输出样例" class="headerlink" title="输出样例"></a>输出样例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1</span><br><span class="line">1</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">2</span><br></pre></td></tr></table></figure><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>后缀自动机可以维护所有子串的出现次数。（具体操作是对每一个<strong>非复制</strong>状态，将其cnt赋值为1，否则为0，最后通过link树进行累计求和）</p><p>对于该题目，需要支持查询最小值、插入元素、删除元素操作，可以用multiset维护。</p><p>因此，每个非复制节点在新建时进行插入操作，被link后进行删除操作即可。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rep(i, l, r) for(int i=l; i&lt;=r; ++i)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 1000006</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line"><span class="keyword">char</span> s[N];</span><br><span class="line"><span class="built_in">multiset</span>&lt;<span class="keyword">int</span>&gt; ms;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SAM</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">state</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="keyword">int</span> len; <span class="comment">// length of longest string</span></span><br><span class="line"><span class="keyword">int</span> link; <span class="comment">// longest nonequivalent suffix</span></span><br><span class="line"><span class="keyword">int</span> nxt[<span class="number">26</span>]; <span class="comment">// next states (default 0)</span></span><br><span class="line"><span class="keyword">bool</span> vis;</span><br><span class="line">&#125;;</span><br><span class="line">state st[N*<span class="number">2</span>]; <span class="comment">// states</span></span><br><span class="line"><span class="keyword">int</span> sz; <span class="comment">// size</span></span><br><span class="line"><span class="keyword">int</span> last; <span class="comment">// last state</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">last = <span class="number">0</span>;</span><br><span class="line">st[<span class="number">0</span>].len = <span class="number">0</span>; <span class="comment">// empty state</span></span><br><span class="line">st[<span class="number">0</span>].link = <span class="number">-1</span>;</span><br><span class="line">st[<span class="number">0</span>].vis = <span class="literal">false</span>;</span><br><span class="line">sz = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">extend</span><span class="params">(<span class="keyword">char</span> c)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> cur = sz++; <span class="comment">// new state</span></span><br><span class="line">st[cur].vis = <span class="literal">false</span>;</span><br><span class="line">st[cur].len = st[last].len + <span class="number">1</span>; <span class="comment">// length</span></span><br><span class="line"><span class="keyword">int</span> p = last;</span><br><span class="line"><span class="keyword">while</span>(p != <span class="number">-1</span> &amp;&amp; !st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>]) &#123;</span><br><span class="line">st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] = cur;</span><br><span class="line">p = st[p].link;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(p == <span class="number">-1</span>) &#123;</span><br><span class="line">st[cur].link = <span class="number">0</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">int</span> q = st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>];</span><br><span class="line"><span class="keyword">if</span>(st[p].len + <span class="number">1</span> == st[q].len) &#123; <span class="comment">// no other state</span></span><br><span class="line">st[cur].link = q;</span><br><span class="line"><span class="keyword">if</span>(!st[q].vis)&#123;</span><br><span class="line">st[q].vis=<span class="literal">true</span>;</span><br><span class="line">ms.erase(ms.find(st[st[q].link].len+<span class="number">1</span>));</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">int</span> clone = sz++;</span><br><span class="line">st[clone] = st[q];</span><br><span class="line">st[clone].len = st[p].len + <span class="number">1</span>;</span><br><span class="line">st[clone].vis = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">if</span>(!st[q].vis) ms.erase(ms.find(st[st[q].link].len+<span class="number">1</span>));</span><br><span class="line"><span class="keyword">while</span>(p != <span class="number">-1</span> &amp;&amp; st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] == q)&#123;</span><br><span class="line">st[p].nxt[c - <span class="string">&#x27;a&#x27;</span>] = clone; <span class="comment">// transfer</span></span><br><span class="line">p = st[p].link;</span><br><span class="line">&#125;</span><br><span class="line">st[q].link = st[cur].link = clone;</span><br><span class="line"><span class="keyword">if</span>(!st[q].vis) ms.insert(st[st[q].link].len+<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">last = cur;</span><br><span class="line">ms.insert(st[st[cur].link].len+<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">SAM a;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%d%s&quot;</span>, &amp;n, s+<span class="number">1</span>);</span><br><span class="line">a.init();</span><br><span class="line">rep(i, <span class="number">1</span>, n)&#123;</span><br><span class="line">a.extend(s[i]);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, *ms.begin());</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;题目描述&quot;&gt;&lt;a href=&quot;#题目描述&quot; class=&quot;headerlink&quot; title=&quot;题目描述&quot;&gt;&lt;/a&gt;题目描述&lt;/h2&gt;&lt;p&gt;如果字符串$s$的子串$s[l..r]$在$s$中只出现一次，那么称它为$s$的&lt;strong&gt;特征子串&lt;/strong&gt;。</summary>
      
    
    
    
    <category term="ACM" scheme="http://abcdhhhh.github.io/categories/ACM/"/>
    
    
    <category term="后缀自动机" scheme="http://abcdhhhh.github.io/tags/%E5%90%8E%E7%BC%80%E8%87%AA%E5%8A%A8%E6%9C%BA/"/>
    
    <category term="字符串" scheme="http://abcdhhhh.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
    
  </entry>
  
  <entry>
    <title>图的计数</title>
    <link href="http://abcdhhhh.github.io/2021/01/29/%E5%9B%BE%E7%9A%84%E8%AE%A1%E6%95%B0/"/>
    <id>http://abcdhhhh.github.io/2021/01/29/%E5%9B%BE%E7%9A%84%E8%AE%A1%E6%95%B0/</id>
    <published>2021-01-29T14:45:43.000Z</published>
    <updated>2021-02-02T13:22:03.858Z</updated>
    
    <content type="html"><![CDATA[<h1 id="无标号计数"><a href="#无标号计数" class="headerlink" title="无标号计数"></a>无标号计数</h1><h2 id="1、二叉树"><a href="#1、二叉树" class="headerlink" title="1、二叉树"></a>1、二叉树</h2><p>设OGF为$H(x)=\sum_{i=0}^{\infty}h_ix^i$。<br>任意一棵大小为$n(n\ge 1)$二叉树去掉根，可以得到两棵大小之和为$n-1$的二叉树。因此$h_n=\sum_{i=0}^{n-1}h_ih_{n-1-i}(n\ge 1)$。</p><p>根据递推关系可列出方程$xH(x)^2-H(x)+1=0$。<br>解得$H(x)=\frac{1-\sqrt{1-4x}}{2x}$。<br>求得$h_n=\frac{\binom{2n}{n}}{n+1}$。</p><h2 id="预备知识：Euler变换"><a href="#预备知识：Euler变换" class="headerlink" title="*预备知识：Euler变换"></a>*预备知识：Euler变换</h2><p>Euler变换在无标号计数中的组合意义相当于有标号计数中的exp，即阶数之和为$n$的结构的任意组合。</p><p>设$F(x)=\sum_{i=0}^{\infty}f_ix^i$。<br>定义$\mathcal{E}(F(x))=\prod_{i=0}^\infty \frac{1}{(1-x^i)^{f_i}}$。<br>上式可化为$\mathcal{E}(F(x))=\exp(\sum_{i=1}^\infty\frac{F(x^i)}{i})$。</p><h2 id="2、有根树"><a href="#2、有根树" class="headerlink" title="2、有根树"></a>2、有根树</h2><p>设OGF为$F(x)=\sum_{i=0}^\infty f_ix^i$。<br>任意一棵大小为$n(n\ge 1)$的有根树去掉根，可以得到若干棵大小之和为$n-1$的有根树。因此$F(x)=x\mathcal{E}(F(x))$。</p><h2 id="2-、无根树"><a href="#2-、无根树" class="headerlink" title="2*、无根树"></a>2*、无根树</h2><p>设有根树的OGF为$F(x)=\sum_{i=0}^\infty f_ix^i$，无根树的OGF为$H(x)=\sum_{i=0}^\infty h_ix^i$。<br>要统计无根树，只需统计以重心为根的有根树。根据重心的定义一个点是重心当且仅当它的每棵子树大小不超过$[\frac{n}{2}]$。<br>因此，一棵树有2个重心当且仅当重心最大子树的大小<strong>恰好</strong>是$\frac{n}{2}$，否则只有1个重心。当树有两个重心时，也要把重心重复计算的情况给减去。<br>因此，$h_n=\begin{cases}f_n-\sum_{k=\frac{n+1}{2}}^{n-1}f_kf_{n-k}&amp;n为奇数\\f_n-\sum_{k=\frac{n}{2}+1}^{n-1}f_kf_{n-k}-\binom{f_{\frac{n}{2}}}{2}&amp;n为偶数\end{cases}$。<br>即$H(x)=F(x)-\frac{1}{2}F(x)^2+F(x^2)$。</p><h1 id="有标号计数"><a href="#有标号计数" class="headerlink" title="有标号计数"></a>有标号计数</h1><h2 id="1、无根树"><a href="#1、无根树" class="headerlink" title="1、无根树"></a>1、无根树</h2><p>由<a href=https://oi-wiki.org/graph/prufer/>Prufer序列</a>和无根树的一一对应关系，得答案$n^{n-2}$。</p><h2 id="1-、有根树"><a href="#1-、有根树" class="headerlink" title="1*、有根树"></a>1*、有根树</h2><p>答案$n^{n-1}$。</p><h2 id="2、无向连通图"><a href="#2、无向连通图" class="headerlink" title="2、无向连通图"></a>2、无向连通图</h2><p>设$n$阶有标号无向连通图有$f_n$种。<br>设$F(x)=\sum_{i=0}^\infty \frac{f_i}{i!}x^i$。<br>则$\exp F(x)=\sum_{i=0}^\infty\frac{2^\binom{i}{2}}{i!}x^i$。<br>即$F(x)=\ln\sum_{i=0}^\infty\frac{2^\binom{i}{2}}{i!}x^i$</p><h2 id="3、点双连通图"><a href="#3、点双连通图" class="headerlink" title="3、点双连通图"></a>3、点双连通图</h2><p>设无向连通图的EGF为$F(x)$，有根无向连通图的EGF为$D(x)$，则$[x^n]F(x)=n[x^n]D(x)$。<br>设点双连通图的EGF为$B(x)$。<br>任意一个大小为$n$的有根无向连通图去掉根都可以得到若干个大小之和为$n-1$的连通块。对每个连通块，考虑根所在的点双连通分量，每个点作为根，都可以向外连出一个有根无向连通图。<br>因此一个连通块的EGF为$\sum_{i=1}^\infty \frac{b_{i+1}D^i(x)}{i!}=B’(D(x))$。<br>因此$D(x)=\exp B’(D(x))$。</p><h2 id="4、边双连通图"><a href="#4、边双连通图" class="headerlink" title="4、边双连通图"></a>4、边双连通图</h2><p>设有根无向连通图的EGF为$D(x)$，边双连通图的EGF为$B(x)$。<br>考虑根所在的边双连通分量，每个点都可以向外连接若干个有根无向连通图的根。<br>因此$D(x)=\sum_{i=1}^\infty \frac{b_ix^i\exp iD(x)}{i!}=B(x\exp D(x))$</p><h2 id="5、仙人掌"><a href="#5、仙人掌" class="headerlink" title="5、仙人掌"></a>5、仙人掌</h2><p>设EGF为$F(x)=\sum_{i=0}^\infty \frac{f_i}{i!}x^i$。<br>$F=x\exp (F+\frac{1}{2}\sum_{i=2}^\infty F^i)=x\exp \frac{F(2-F)}{2(1-F)}$</p><h2 id="6、DAG"><a href="#6、DAG" class="headerlink" title="6、DAG"></a>6、DAG</h2><p>设EGF为$F(x)=\sum_{i=0}^\infty \frac{f_i}{i!}x^i$。<br>$f_n=\sum_{i=1}^n(-1)^{i-1}\binom{n}{i}2^{i(n-i)}f_{n-i}$。</p><h2 id="7、欧拉图"><a href="#7、欧拉图" class="headerlink" title="7、欧拉图"></a>7、欧拉图</h2><p>设EGF为$F(x)=\sum_{i=0}^\infty \frac{f_i}{i!}x^i$。每个点度数均为偶数的图的EGF为$G(x)=\sum_{i=0}^\infty \frac{g_i}{i!}x^i$。<br>对于任意一个$n-1$阶的图，都可以新加一个点$n$，与图中所有度数为奇数的点连边。<br>因此$g_n=2^\binom{n-1}{2}$。<br>而$G(x)=\exp F(x)$。<br>因此$F(x)=\ln G(x)$。</p>]]></content>
    
    
    <summary type="html">永远学不会的多项式，永远理不清的递推关系</summary>
    
    
    
    <category term="组合数学" scheme="http://abcdhhhh.github.io/categories/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/"/>
    
    
    <category term="多项式" scheme="http://abcdhhhh.github.io/tags/%E5%A4%9A%E9%A1%B9%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>监督学习</title>
    <link href="http://abcdhhhh.github.io/2021/01/29/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>http://abcdhhhh.github.io/2021/01/29/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</id>
    <published>2021-01-29T14:45:43.000Z</published>
    <updated>2021-02-08T02:38:42.223Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p><pre class="mermaid">graph TD;ts(Training set);la(Learning algorithm);h(hypothesis function);1((x))2((y))ts-->la-->h;1-->h-->2;</pre></p><h1 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h1><p>$\{(x^{(i)},y^{(i)})|i=1,2,…,m\}$<br>$x_j^{(i)}$表示第$i$个训练数据的第$j$个特征。<br>记$X=\begin{bmatrix}x^{(1)}&amp;x^{(2)}&amp;…&amp;x^{(m)}\end{bmatrix}^T=\begin{bmatrix}x_0^{(1)}&amp;x_1^{(1)}&amp;…&amp;x_n^{(1)}\\x_0^{(2)}&amp;x_1^{(2)}&amp;…&amp;x_n^{(2)}\...&amp;…&amp;…&amp;…\\x_0^{(m)}&amp;x_1^{(m)}&amp;…&amp;x_n^{(m)}\end{bmatrix}$，$y=\begin{bmatrix}y^{(1)}\\y^{(2)}\...\\y^{(m)}\end{bmatrix}$。</p><h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h2><p>$x_i:=\frac{x_i-\mu_i}{s_i}$<br>其中$\mu_i$为平均值，$s_i$为标准差。</p><h1 id="回归问题——线性回归"><a href="#回归问题——线性回归" class="headerlink" title="回归问题——线性回归"></a>回归问题——线性回归</h1><p>令$x_0=1$，$x=\begin{bmatrix}x_0\\x_1\...\\x_n\end{bmatrix}$，$\theta=\begin{bmatrix}\theta_0\\\theta_1\...\\\theta_n\end{bmatrix}$。<br>假设函数：$h_\theta (x)=\theta^Tx$。</p><p>记$h=\begin{bmatrix}h_\theta({x^{(1)})}\\h_\theta({x^{(2)})}\...\\h_\theta({x^{(m)})}\end{bmatrix}=X\theta$。<br>总代价函数：$J(\theta)=\frac{1}{2m}||h-y||^2=\frac{1}{2m}||X\theta-y||^2$</p><h2 id="tip-多项式回归转线性回归"><a href="#tip-多项式回归转线性回归" class="headerlink" title="tip: 多项式回归转线性回归"></a>tip: 多项式回归转线性回归</h2><p>将$x_1^2, x_1x_2^3$等高次项也作为特征。</p><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>不断迭代：$\theta :=\theta-\alpha \nabla J(\theta)$<br>其中：</p><ul><li>$\alpha$为学习速率</li><li>$\nabla J(\theta)=\frac{1}{m}X^T(X\theta-y)$为梯度</li></ul><h2 id="一般方程"><a href="#一般方程" class="headerlink" title="一般方程"></a>一般方程</h2><p>$\theta=(X^TX)^{-1}X^Ty$<br>当$X^TX$不可逆时，需思考特征是否过多（比如$m\le n$）。</p><h1 id="二分类问题——logistic回归"><a href="#二分类问题——logistic回归" class="headerlink" title="二分类问题——logistic回归"></a>二分类问题——logistic回归</h1><p>sigmoid函数：$g(z)=\frac{1}{1+e^{-z}}$。<br>hypothesis函数：$h_\theta (x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}=P(y=1|x;\theta)$。<br>记$h=g(X\theta)$。</p><p>决策函数：$y=[h_\theta(x)&gt;0.5]$<br>决策边界： $h_\theta(x)=0.5$，即$\theta^Tx=0$。</p><p>代价函数：$\text{Cost}(h_\theta(x),y)=\begin{cases}-\log(h_\theta(x))&amp;y=1\-\log(1-h_\theta(x))&amp; y=0\end{cases}\\=-y\log(h_\theta(x))-(1-y)\log(1-h_\theta(x))$</p><p>总代价函数：$J(\theta)=\frac{1}{m}\sum_{i=1}^m\text{Cost}(h_\theta(x^{(i)}),y^{(i)})\\=-\frac{1}{m}(y^T\log(h)+(1-y)^T\log(1-h))\\=\frac{1}{m}(y^T\log(1+e^{-X\theta})+(1-y)^T\log(1+e^{X\theta}))$</p><h2 id="梯度下降法-1"><a href="#梯度下降法-1" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>不断迭代：$\theta :=\theta-\alpha \nabla J(\theta)$<br>其中：</p><ul><li>$\nabla J(\theta)=\frac{1}{m}X^T(h-y)$<h2 id="tip-多分类转二分类"><a href="#tip-多分类转二分类" class="headerlink" title="tip: 多分类转二分类"></a>tip: 多分类转二分类</h2>面对每个新的数据集，都逐类进行检验（把要检验的类当作1，其余当作0），选择可能性最高的那类。</li></ul><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>增加penalty以控制$\theta$规模。（$\theta_0$除外）<br>回归问题<br>$J(\theta)=\frac{1}{2m}||h-y||^2+\frac{\lambda}{2m}(||\theta||^2-\theta_0^2)$<br>分类问题</p><p>$J(\theta)=-\frac{1}{m}(y^T\log(h)+(1-y)^T\log(1-h))+\frac{\lambda}{2m}(||\theta||^2-\theta_0^2)$</p><p>$\theta_j :=\theta_j(1-\alpha\frac{\lambda}{m})-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} (j\ne 0)$</p><p>一般方程<br>$\theta=(X^TX+\lambda \begin{bmatrix}0&amp;O\\O&amp;I_n\end{bmatrix})^{-1}X^Ty$<br>（还可以解决矩阵不可逆问题）</p><h2 id="overfit与underfit"><a href="#overfit与underfit" class="headerlink" title="overfit与underfit"></a>overfit与underfit</h2><div class="table-container"><table><thead><tr><th></th><th>overfit: high variance</th><th>underfit: high bias</th></tr></thead><tbody><tr><td></td><td>$J_{CV}&gt;&gt;J_{train}&gt;0$</td><td>$J_{CV}&gt;J_{train}&gt;&gt;0$</td></tr><tr><td>fix</td><td>fewer features, <strong>more examples</strong>, increase $\lambda$</td><td>more/polynomial features, decrease $\lambda$</td></tr></tbody></table></div>]]></content>
    
    
    <summary type="html">举一反三的原理</summary>
    
    
    
    <category term="机器学习" scheme="http://abcdhhhh.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="回归分析" scheme="http://abcdhhhh.github.io/tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>神经网络中的反向传播算法</title>
    <link href="http://abcdhhhh.github.io/2021/01/29/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/"/>
    <id>http://abcdhhhh.github.io/2021/01/29/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/</id>
    <published>2021-01-29T14:45:43.000Z</published>
    <updated>2021-02-07T09:40:29.511Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p>神经网络是一个多层感知机。从输入到输出共有$L$层，第$l$层$a^{(l)}$有$s_l$个unit。（$K$分类问题中$s_L=K$）</p><p>相邻两层之间的转移是Logistic回归（一个带偏移的线性变换+一个sigmoid函数）：</p><p>$z^{(l+1)}=W^{(l)}a^{(l)}+b^{(l)}, a^{(l+1)}=g(z^{(l+1)})$</p><p>其中$W^{(l)}\in R^{s_{l+1}\times s_l}, b^{(l)}\in R^{s_{l+1}}$，$g(z)=\frac{1}{1+e^{-z}}$。</p><p>$J(\Theta)=-\text{mean}(y^T\log h-(1-y)^T\log (1-h))+||W||^2$</p><p>我们的目标是求$\Theta$以最小化$J(\Theta)$。</p><p>该过程采用梯度下降法，因此需要知道每一步的$\frac{\partial}{\partial W_{i,j}^{(l)}}J(\Theta)$以及$\frac{\partial}{\partial b_{i}^{(l)}}J(\Theta)$，而这可以利用反向传播算法算出。</p><h2 id="预备知识：-Hadamard积"><a href="#预备知识：-Hadamard积" class="headerlink" title="预备知识： Hadamard积"></a>预备知识： Hadamard积</h2><p>即对应元素的乘积。</p><p>$S_{n\times m}\circ T_{n\times m}=\begin{bmatrix}s_{11}t_{11}&amp;s_{12}t_{12}&amp;…&amp;s_{1m}t_{1m}\\ s_{21}t_{21}&amp;s_{22}t_{22}&amp;…&amp;s_{2m}t_{2m}\\ …&amp;…&amp;…&amp;…\\ s_{n1}t_{n1}&amp;s_{n2}t_{n2}&amp;…&amp;s_{nm}t_{nm}\end{bmatrix}$</p><h1 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h1><p>$g’(z)=\frac{e^{-z}}{(1+e^{-z})^2}=g(z)(1-g(z))$</p><p>$\Delta a^{(l+1)}=\Delta z^{(l+1)}\circ g’(z^{(l+1)})=\Delta a^{(l)}W^{(l)}\circ a^{(l+1)}\circ (1-a^{(l+1)})$</p><p>可以从后往前求出每层的偏差。</p><p>$\frac{\partial h}{\partial W_{i,j}^{(l)}}=\Delta a_{j}^{(l)}a_i^{(l)}$</p><p>下面是ex4中nnCostFunction.m的代码：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[J grad]</span> = <span class="title">nnCostFunction</span><span class="params">(nn_params, ...</span></span></span><br><span class="line"><span class="function"><span class="params">                                   input_layer_size, ...</span></span></span><br><span class="line"><span class="function"><span class="params">                                   hidden_layer_size, ...</span></span></span><br><span class="line"><span class="function"><span class="params">                                   num_labels, ...</span></span></span><br><span class="line"><span class="function"><span class="params">                                   X, y, lambda)</span></span></span><br><span class="line"><span class="comment">%NNCOSTFUNCTION Implements the neural network cost function for a two layer</span></span><br><span class="line"><span class="comment">%neural network which performs classification</span></span><br><span class="line"><span class="comment">%   [J grad] = NNCOSTFUNCTON(nn_params, hidden_layer_size, num_labels, ...</span></span><br><span class="line"><span class="comment">%   X, y, lambda) computes the cost and gradient of the neural network. The</span></span><br><span class="line"><span class="comment">%   parameters for the neural network are &quot;unrolled&quot; into the vector</span></span><br><span class="line"><span class="comment">%   nn_params and need to be converted back into the weight matrices. </span></span><br><span class="line"><span class="comment">% </span></span><br><span class="line"><span class="comment">%   The returned parameter grad should be a &quot;unrolled&quot; vector of the</span></span><br><span class="line"><span class="comment">%   partial derivatives of the neural network.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices</span></span><br><span class="line"><span class="comment">% for our 2 layer neural network</span></span><br><span class="line">Theta1 = <span class="built_in">reshape</span>(nn_params(<span class="number">1</span>:hidden_layer_size * (input_layer_size + <span class="number">1</span>)), ...</span><br><span class="line">                 hidden_layer_size, (input_layer_size + <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">Theta2 = <span class="built_in">reshape</span>(nn_params((<span class="number">1</span> + (hidden_layer_size * (input_layer_size + <span class="number">1</span>))):<span class="keyword">end</span>), ...</span><br><span class="line">                 num_labels, (hidden_layer_size + <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">% Setup some useful variables</span></span><br><span class="line">m = <span class="built_in">size</span>(X, <span class="number">1</span>);</span><br><span class="line">         </span><br><span class="line"><span class="comment">% You need to return the following variables correctly </span></span><br><span class="line">J = <span class="number">0</span>;</span><br><span class="line">Theta1_grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(Theta1));</span><br><span class="line">Theta2_grad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(Theta2));</span><br><span class="line"></span><br><span class="line"><span class="comment">% ====================== YOUR CODE HERE ======================</span></span><br><span class="line"><span class="comment">% Instructions: You should complete the code by working through the</span></span><br><span class="line"><span class="comment">%               following parts.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Part 1: Feedforward the neural network and return the cost in the</span></span><br><span class="line"><span class="comment">%         variable J. After implementing Part 1, you can verify that your</span></span><br><span class="line"><span class="comment">%         cost function computation is correct by verifying the cost</span></span><br><span class="line"><span class="comment">%         computed in ex4.m</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Part 2: Implement the backpropagation algorithm to compute the gradients</span></span><br><span class="line"><span class="comment">%         Theta1_grad and Theta2_grad. You should return the partial derivatives of</span></span><br><span class="line"><span class="comment">%         the cost function with respect to Theta1 and Theta2 in Theta1_grad and</span></span><br><span class="line"><span class="comment">%         Theta2_grad, respectively. After implementing Part 2, you can check</span></span><br><span class="line"><span class="comment">%         that your implementation is correct by running checkNNGradients</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">%         Note: The vector y passed into the function is a vector of labels</span></span><br><span class="line"><span class="comment">%               containing values from 1..K. You need to map this vector into a </span></span><br><span class="line"><span class="comment">%               binary vector of 1&#x27;s and 0&#x27;s to be used with the neural network</span></span><br><span class="line"><span class="comment">%               cost function.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">%         Hint: We recommend implementing backpropagation using a for-loop</span></span><br><span class="line"><span class="comment">%               over the training examples if you are implementing it for the </span></span><br><span class="line"><span class="comment">%               first time.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Part 3: Implement regularization with the cost function and gradients.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">%         Hint: You can implement this around the code for</span></span><br><span class="line"><span class="comment">%               backpropagation. That is, you can compute the gradients for</span></span><br><span class="line"><span class="comment">%               the regularization separately and then add them to Theta1_grad</span></span><br><span class="line"><span class="comment">%               and Theta2_grad from Part 2.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line">A1 = [<span class="built_in">ones</span>(m,<span class="number">1</span>), X];</span><br><span class="line">Z2 = A1*Theta1&#x27;;</span><br><span class="line">A2 = [<span class="built_in">ones</span>(m,<span class="number">1</span>), sigmoid(Z2)];</span><br><span class="line">Z3 = A2*Theta2&#x27;;</span><br><span class="line">A3 = sigmoid(Z3);</span><br><span class="line">h = A3;</span><br><span class="line"></span><br><span class="line">yk = (<span class="number">1</span>:num_labels)==y;</span><br><span class="line"></span><br><span class="line">J = sum(-yk.*<span class="built_in">log</span>(h)-(<span class="number">1</span>-yk).*<span class="built_in">log</span>(<span class="number">1</span>-h), <span class="string">&#x27;all&#x27;</span>)/m+lambda/<span class="number">2</span>/m*(sum(Theta1(:,<span class="number">2</span>:<span class="keyword">end</span>).^<span class="number">2</span>, <span class="string">&#x27;all&#x27;</span>)+sum(Theta2(:,<span class="number">2</span>:<span class="keyword">end</span>).^<span class="number">2</span>, <span class="string">&#x27;all&#x27;</span>));</span><br><span class="line"></span><br><span class="line">delta3 = h-yk;</span><br><span class="line">delta2 = delta3*Theta2(:,<span class="number">2</span>:<span class="keyword">end</span>).* sigmoidGradient(Z2);</span><br><span class="line">Theta1_grad=delta2&#x27;*A1./m;</span><br><span class="line">Theta2_grad=delta3&#x27;*A2./m;</span><br><span class="line"></span><br><span class="line">Theta1_grad(:,<span class="number">2</span>:<span class="keyword">end</span>)=Theta1_grad(:,<span class="number">2</span>:<span class="keyword">end</span>)+lambda/m*Theta1(:,<span class="number">2</span>:<span class="keyword">end</span>);</span><br><span class="line">Theta2_grad(:,<span class="number">2</span>:<span class="keyword">end</span>)=Theta2_grad(:,<span class="number">2</span>:<span class="keyword">end</span>)+lambda/m*Theta2(:,<span class="number">2</span>:<span class="keyword">end</span>);</span><br><span class="line"><span class="comment">% -------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% =========================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Unroll gradients</span></span><br><span class="line">grad = [Theta1_grad(:) ; Theta2_grad(:)];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">多层感知机</summary>
    
    
    
    <category term="机器学习" scheme="http://abcdhhhh.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>小记</title>
    <link href="http://abcdhhhh.github.io/2021/01/29/%E5%B0%8F%E8%AE%B0/"/>
    <id>http://abcdhhhh.github.io/2021/01/29/%E5%B0%8F%E8%AE%B0/</id>
    <published>2021-01-29T10:08:45.000Z</published>
    <updated>2021-02-02T13:24:46.299Z</updated>
    
    <content type="html"><![CDATA[<p>没啥特别的目的，主要想体验一下建站是一种什么感觉<del>以及不喜欢CSDN的界面风格</del>。<br>关于写啥内容，暂时还没啥明确的想法。希望能早日写出一些有价值的东西吧。</p><p>没有太多可说的，那就放一首歌吧。</p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1389794615&auto=1&height=66"></iframe>]]></content>
    
    
    <summary type="html">写在建站之后</summary>
    
    
    
    <category term="随笔" scheme="http://abcdhhhh.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
</feed>
